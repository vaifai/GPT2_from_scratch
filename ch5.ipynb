{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "732208e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.9.2\n",
      "torch version: 2.5.1\n",
      "tiktoken version: 0.9.0\n",
      "numpy version: 1.26.4\n",
      "tensorflow version: 2.19.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\", \"torch\", \"tiktoken\", \"numpy\", \"tensorflow\"]\n",
    "\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e9aa174",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from gpt import GPTModel\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.1,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval();  # Disable dropout during inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c6626f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you up paraduxeHandle appropriation pigment Primordial audiences smugglingRAMlevision\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "from gpt import generate_text_simple\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text)\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    decoded_text = tokenizer.decode(token_ids.squeeze(0).tolist())\n",
    "    return decoded_text\n",
    "\n",
    "start_context = \"Every effort moves you up\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a97769f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]])   #  \"I really like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [1107,  588, 11311]]) #  \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16eefb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n",
      "tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n",
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "probs = torch.softmax(logits, dim=-1)\n",
    "print(probs.shape)\n",
    "\n",
    "token_ids = torch.argmax(probs, dim=-1, keepdim=True)\n",
    "print(token_ids)\n",
    "\n",
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1:\"\n",
    "      f\" {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3809421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([7.4541e-05, 3.1061e-05, 1.1563e-05])\n",
      "Text 2: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probs[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probs[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c9313ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
     ]
    }
   ],
   "source": [
    "# Compute logarithm of all token probabilities\n",
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e143c530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.7940)\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average probability for each token\n",
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de20bd14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2522a349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0,1)\n",
    "targets_flat = targets.flatten()\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5d52535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "351b7961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(48725.8203)\n"
     ]
    }
   ],
   "source": [
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "320d0817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "from attention import create_dataloader_v1\n",
    "\n",
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text_data = f.read()\n",
    "\n",
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(f\"Total characters: {total_characters}\")\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3259f79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.9\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d480a736",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d1dda3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "\n",
    "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the training loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"increase the `training_ratio`\")\n",
    "\n",
    "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the validation loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"decrease the `training_ratio`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eeae5b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "tensor([[   40,   367,  2885,  1464,  1807,  3619,   402,   271, 10899,  2138,\n",
      "           257,  7026, 15632,   438,  2016,   257,   922,  5891,  1576,   438,\n",
      "           568,   340,   373,   645,  1049,  5975,   284,   502,   284,  3285,\n",
      "           326,    11,   287,   262,  6001,   286,   465, 13476,    11,   339,\n",
      "           550,  5710,   465, 12036,    11,  6405,   257,  5527, 27075,    11,\n",
      "           290,  4920,  2241,   287,   257,  4489,    64,   319,   262, 34686,\n",
      "         41976,    13,   357, 10915,   314,  2138,  1807,   340,   561,   423,\n",
      "           587, 10598,   393, 28537,  2014,   198,   198,     1,   464,  6001,\n",
      "           286,   465, 13476,     1,   438,  5562,   373,   644,   262,  1466,\n",
      "          1444,   340,    13,   314,   460,  3285,  9074,    13, 46606,   536,\n",
      "          5469,   438, 14363,   938,  4842,  1650,   353,   438,  2934,   489,\n",
      "          3255,   465, 48422,   540,   450,    67,  3299,    13,   366,  5189,\n",
      "          1781,   340,   338,  1016,   284,  3758,   262,  1988,   286,   616,\n",
      "          4286,   705,  1014,   510,    26,   475,   314,   836,   470,   892,\n",
      "           286,   326,    11,  1770,    13,  8759,  2763,   438,  1169,  2994,\n",
      "           284,   943, 17034,   318,   477,   314,   892,   286,   526,   383,\n",
      "          1573,    11,   319,  9074,    13,   536,  5469,   338, 11914,    11,\n",
      "         33096,   663,  4808,  3808,    62,   355,   996,   484,   547, 12548,\n",
      "           287,   281, 13079,   410, 12523,   286, 22353,    13,   843,   340,\n",
      "           373,   407,   691,   262,  9074,    13,   536, 48819,   508, 25722,\n",
      "           276,    13, 11161,   407,   262, 40123, 18113,   544,  9325,   701,\n",
      "            11,   379,   262,   938,   402,  1617,   261, 12917,   905,    11,\n",
      "          5025,   502,   878,   402,   271, 10899,   338,   366, 31640,    12,\n",
      "            67, 20811,     1,   284,   910,    11,   351, 10953,   287,   607,\n",
      "          2951,    25,   366,  1135,  2236,   407,   804,  2402,   663,   588,\n",
      "           757, 13984,   198,   198,  5779, 28112],\n",
      "        [41186, 39614,  1386,    11,   287,   262, 13203,  5482,  1044,   276,\n",
      "          5739,    13,   383,  5019, 19001,   286,   262,  5739,  1444,   510,\n",
      "           477,   402,   271, 10899,   338,  1613,     0,   198,   198, 27034,\n",
      "            13,   402,   271, 10899,  9859,   736,   262,  4324,    12,    66,\n",
      "          3325,  1299,    11,  3888,  7263,   257,  4808,    73,   446,   259,\n",
      "         13235,    62,  1336,   286, 11398, 35560,  1000,   292,    11,  7121,\n",
      "           281,  3211,    12, 16337,  1497,    11,   290,   531,    25,   366,\n",
      "          1532,   345,  1302,   994,   345,   460,   655,  6687,   284,   766,\n",
      "           340,    13,   314,   550,   340,   625,   262, 24818,   417,    12,\n",
      "         12239,    11,   475,   339,  3636,   470,  1309,   340,  2652,   526,\n",
      "           198,   198,  5297,   438,    40,   714,   655,  6687,   284,   766,\n",
      "           340,   438,  1169,   717, 18560,   286,  3619,   338,   314,   550,\n",
      "          1683,   550,   284, 14022,   616,  2951,   625,     0, 19672,   484,\n",
      "           550,   262,  1295,   286, 15393,   438, 16706,   262,  4318,  6103,\n",
      "           287,   257, 14005,  7872,   393,  4808, 13698, 10322,  6532,    62,\n",
      "          8263,    12,  3823,    11,   393,   257, 36364,  1396,   417,  4624,\n",
      "           523,   326,   340,  1718,   262,  1657,   832, 41160,   286,  1468,\n",
      "          9932,   316,   666,   966,    13,   383,   517, 12949,  1295,  2627,\n",
      "           262,  4286,  1365,    26,  1865,    11,   355,   616,  2951,  6348,\n",
      "         23840,   284,   262,  2063,    12,  2971,    11,   477,   262, 16704,\n",
      "         14482,  1625,   503,   438,   439,   262, 10818, 20597, 32192,   355,\n",
      "          2709,   330,   871,    11,   262, 15910,   286, 16153,   312,   328,\n",
      "          3780,   416,   543,    11,   351,   884,  2784,  9830,  5032,    11,\n",
      "           339,  5257,   284, 36583,  3241,   422,   262,  1103,  1597,   286,\n",
      "           262,  4286,   284,   617,  2495, 11331,  2768,   590,   286,  3703,\n",
      "            13,  9074,    13,   402,   271, 10899]]) tensor([[  367,  2885,  1464,  1807,  3619,   402,   271, 10899,  2138,   257,\n",
      "          7026, 15632,   438,  2016,   257,   922,  5891,  1576,   438,   568,\n",
      "           340,   373,   645,  1049,  5975,   284,   502,   284,  3285,   326,\n",
      "            11,   287,   262,  6001,   286,   465, 13476,    11,   339,   550,\n",
      "          5710,   465, 12036,    11,  6405,   257,  5527, 27075,    11,   290,\n",
      "          4920,  2241,   287,   257,  4489,    64,   319,   262, 34686, 41976,\n",
      "            13,   357, 10915,   314,  2138,  1807,   340,   561,   423,   587,\n",
      "         10598,   393, 28537,  2014,   198,   198,     1,   464,  6001,   286,\n",
      "           465, 13476,     1,   438,  5562,   373,   644,   262,  1466,  1444,\n",
      "           340,    13,   314,   460,  3285,  9074,    13, 46606,   536,  5469,\n",
      "           438, 14363,   938,  4842,  1650,   353,   438,  2934,   489,  3255,\n",
      "           465, 48422,   540,   450,    67,  3299,    13,   366,  5189,  1781,\n",
      "           340,   338,  1016,   284,  3758,   262,  1988,   286,   616,  4286,\n",
      "           705,  1014,   510,    26,   475,   314,   836,   470,   892,   286,\n",
      "           326,    11,  1770,    13,  8759,  2763,   438,  1169,  2994,   284,\n",
      "           943, 17034,   318,   477,   314,   892,   286,   526,   383,  1573,\n",
      "            11,   319,  9074,    13,   536,  5469,   338, 11914,    11, 33096,\n",
      "           663,  4808,  3808,    62,   355,   996,   484,   547, 12548,   287,\n",
      "           281, 13079,   410, 12523,   286, 22353,    13,   843,   340,   373,\n",
      "           407,   691,   262,  9074,    13,   536, 48819,   508, 25722,   276,\n",
      "            13, 11161,   407,   262, 40123, 18113,   544,  9325,   701,    11,\n",
      "           379,   262,   938,   402,  1617,   261, 12917,   905,    11,  5025,\n",
      "           502,   878,   402,   271, 10899,   338,   366, 31640,    12,    67,\n",
      "         20811,     1,   284,   910,    11,   351, 10953,   287,   607,  2951,\n",
      "            25,   366,  1135,  2236,   407,   804,  2402,   663,   588,   757,\n",
      "         13984,   198,   198,  5779, 28112, 10197],\n",
      "        [39614,  1386,    11,   287,   262, 13203,  5482,  1044,   276,  5739,\n",
      "            13,   383,  5019, 19001,   286,   262,  5739,  1444,   510,   477,\n",
      "           402,   271, 10899,   338,  1613,     0,   198,   198, 27034,    13,\n",
      "           402,   271, 10899,  9859,   736,   262,  4324,    12,    66,  3325,\n",
      "          1299,    11,  3888,  7263,   257,  4808,    73,   446,   259, 13235,\n",
      "            62,  1336,   286, 11398, 35560,  1000,   292,    11,  7121,   281,\n",
      "          3211,    12, 16337,  1497,    11,   290,   531,    25,   366,  1532,\n",
      "           345,  1302,   994,   345,   460,   655,  6687,   284,   766,   340,\n",
      "            13,   314,   550,   340,   625,   262, 24818,   417,    12, 12239,\n",
      "            11,   475,   339,  3636,   470,  1309,   340,  2652,   526,   198,\n",
      "           198,  5297,   438,    40,   714,   655,  6687,   284,   766,   340,\n",
      "           438,  1169,   717, 18560,   286,  3619,   338,   314,   550,  1683,\n",
      "           550,   284, 14022,   616,  2951,   625,     0, 19672,   484,   550,\n",
      "           262,  1295,   286, 15393,   438, 16706,   262,  4318,  6103,   287,\n",
      "           257, 14005,  7872,   393,  4808, 13698, 10322,  6532,    62,  8263,\n",
      "            12,  3823,    11,   393,   257, 36364,  1396,   417,  4624,   523,\n",
      "           326,   340,  1718,   262,  1657,   832, 41160,   286,  1468,  9932,\n",
      "           316,   666,   966,    13,   383,   517, 12949,  1295,  2627,   262,\n",
      "          4286,  1365,    26,  1865,    11,   355,   616,  2951,  6348, 23840,\n",
      "           284,   262,  2063,    12,  2971,    11,   477,   262, 16704, 14482,\n",
      "          1625,   503,   438,   439,   262, 10818, 20597, 32192,   355,  2709,\n",
      "           330,   871,    11,   262, 15910,   286, 16153,   312,   328,  3780,\n",
      "           416,   543,    11,   351,   884,  2784,  9830,  5032,    11,   339,\n",
      "          5257,   284, 36583,  3241,   422,   262,  1103,  1597,   286,   262,\n",
      "          4286,   284,   617,  2495, 11331,  2768,   590,   286,  3703,    13,\n",
      "          9074,    13,   402,   271, 10899,    11]])\n",
      "tensor([[  198,  1544, 13818,  4622,    11,  1231, 35987,    11,   290,  7121,\n",
      "           530,   286,   262,  2769,  3211,    12, 49655,  2651,    13,   366,\n",
      "          1858,    25,   787,  3511,  6792,   438,   392,   994,   389,   262,\n",
      "         33204,   345,   588,   526,   198,   198,  1544,  4624,   606,   379,\n",
      "           616, 22662,   290,  3767,   284, 27776,   510,   290,   866,   262,\n",
      "          2119,    11, 12225,   783,   290,   788, 11061,   262,  4286,    13,\n",
      "           198,   198,     1,  2437,   340,  3022,    30,   314,   460,  1560,\n",
      "           345,   287,  1936,  2431,   438,   392,   340,  1422,   470,  1011,\n",
      "           881,  2392,   284,  1645,    13,   764,   764,   764,   314,   460,\n",
      "          3505,   783,   703,  6655,   290, 10607,   314,   373,   618,   314,\n",
      "          1392,  9074,    13,   520,  5493,   338,  3465,    13,  3226,  1781,\n",
      "            11,  2769,   866,    11,   314,   550,  1464,  4808, 31985,    62,\n",
      "           612,   373,   645,   530,   588,   683,   438,  8807,   314,   550,\n",
      "          3750,   351,   262,  4269,    11, 22211,   262,  6678, 40315, 10455,\n",
      "           546,   683,    11, 10597,   314,  2063,  1392,   284,   892,   339,\n",
      "           373,   257,  5287,    11,   530,   286,   262,  1611,   326,   389,\n",
      "          1364,  2157,    13,  2750,   449,   659,    11,   290,   339,  4808,\n",
      "          9776,    62,  1364,  2157,   438, 13893,   339,   550,  1282,   284,\n",
      "          2652,     0,   383,  1334,   286,   514,   550,   284,  1309,  6731,\n",
      "           307, 17676,  1863,   393,   467,   739,    11,   475,   339,   373,\n",
      "          1029,  2029,   262,  1459,   438,   261, 45697, 19369,    11,   355,\n",
      "           345,   910,    13,   198,   198,     1,  5779,    11,   314,  1816,\n",
      "           572,   284,   262,  2156,   287,   616,   749, 34372, 10038,   438,\n",
      "         34330,  3888,    11,  4453, 20927,   502,    11,   379,   262,  3108,\n",
      "           418,   286,  3595,   520,  5493,   338,  3451,   286,  5287,   852,\n",
      "         37492,   416,   262, 13476,   286,   616],\n",
      "        [  503,  4291,   262,  4252, 18250,  8812,   558,    13,   198,   198,\n",
      "            40, 27846,   706,   683,    11,  7425,   416,   465,   938,  1573,\n",
      "            13, 12622, 41379,   293,   373,    11,   287,  1109,    11,  5033,\n",
      "           262,   582,   286,   262,  2589,   438,   292,  3619,  2241,    11,\n",
      "           530,  1244,  1234,   340,    11,   550,   587,   262,   582,   286,\n",
      "           262,  1711,    13,   383,  7099,  6802,   373,   531,   284,   423,\n",
      "          7042,  2241,   379,   616,  1545,   338,  3625,    11,   290,   314,\n",
      "         14028,   611,   257,   256, 11912,   286, 35394,   739, 10724,   262,\n",
      "          6846,   338, 11428,   450,    67,  3299,    13,   887,   645,   438,\n",
      "          1640,   340,   373,   407, 10597,   706,   326,  1785,   326,   262,\n",
      "          4808, 13698, 10322,  6532,    62,  8263,    12,  9649,   550,  9258,\n",
      "           284,  3359,   511,   366,  8642,   521,   829,   526,   198,   198,\n",
      "            40,  2900,   284,  9074,    13,   402,   271, 10899,    11,   508,\n",
      "           550, 18459,  1068,   284,  1577,   257, 23844,   286,  7543,   284,\n",
      "           607,   599,  6321,   287,   262, 17423,    12,  3823,    13,   198,\n",
      "           198,     1,  5195,  4808, 10134,    62,   339,   442, 17758, 12036,\n",
      "          1701,   314,  1965, 25891,    13,   198,   198,  3347,  4376,   607,\n",
      "         26928,   351,   257,  9254,   286,   922,    12, 17047,  8167,  5975,\n",
      "            13,   198,   198,     1,  5812,    11,   339,  1595,   470,  4808,\n",
      "         14150,    62,   284,   783,    11,   345,   760,    26,   290,   314,\n",
      "           765,   683,   284,  2883,  2241,   553,   673,   531,  2407,  2391,\n",
      "            13,   198,   198,    40,  3114,   546,   262, 40894,  2330,    12,\n",
      "          6839, 11978,  2119,    11,   351,   663,  4808, 44769,  8270,    12,\n",
      "           332,   660,    62,   410,  1386, 20394,   262, 23755,   286,   262,\n",
      "         14005,  1801,  2093, 41160,    11,   290,   663, 45592,    12, 14792,\n",
      "          1613,  1424,   287, 19217, 24887, 13431]]) tensor([[ 1544, 13818,  4622,    11,  1231, 35987,    11,   290,  7121,   530,\n",
      "           286,   262,  2769,  3211,    12, 49655,  2651,    13,   366,  1858,\n",
      "            25,   787,  3511,  6792,   438,   392,   994,   389,   262, 33204,\n",
      "           345,   588,   526,   198,   198,  1544,  4624,   606,   379,   616,\n",
      "         22662,   290,  3767,   284, 27776,   510,   290,   866,   262,  2119,\n",
      "            11, 12225,   783,   290,   788, 11061,   262,  4286,    13,   198,\n",
      "           198,     1,  2437,   340,  3022,    30,   314,   460,  1560,   345,\n",
      "           287,  1936,  2431,   438,   392,   340,  1422,   470,  1011,   881,\n",
      "          2392,   284,  1645,    13,   764,   764,   764,   314,   460,  3505,\n",
      "           783,   703,  6655,   290, 10607,   314,   373,   618,   314,  1392,\n",
      "          9074,    13,   520,  5493,   338,  3465,    13,  3226,  1781,    11,\n",
      "          2769,   866,    11,   314,   550,  1464,  4808, 31985,    62,   612,\n",
      "           373,   645,   530,   588,   683,   438,  8807,   314,   550,  3750,\n",
      "           351,   262,  4269,    11, 22211,   262,  6678, 40315, 10455,   546,\n",
      "           683,    11, 10597,   314,  2063,  1392,   284,   892,   339,   373,\n",
      "           257,  5287,    11,   530,   286,   262,  1611,   326,   389,  1364,\n",
      "          2157,    13,  2750,   449,   659,    11,   290,   339,  4808,  9776,\n",
      "            62,  1364,  2157,   438, 13893,   339,   550,  1282,   284,  2652,\n",
      "             0,   383,  1334,   286,   514,   550,   284,  1309,  6731,   307,\n",
      "         17676,  1863,   393,   467,   739,    11,   475,   339,   373,  1029,\n",
      "          2029,   262,  1459,   438,   261, 45697, 19369,    11,   355,   345,\n",
      "           910,    13,   198,   198,     1,  5779,    11,   314,  1816,   572,\n",
      "           284,   262,  2156,   287,   616,   749, 34372, 10038,   438, 34330,\n",
      "          3888,    11,  4453, 20927,   502,    11,   379,   262,  3108,   418,\n",
      "           286,  3595,   520,  5493,   338,  3451,   286,  5287,   852, 37492,\n",
      "           416,   262, 13476,   286,   616, 12036],\n",
      "        [ 4291,   262,  4252, 18250,  8812,   558,    13,   198,   198,    40,\n",
      "         27846,   706,   683,    11,  7425,   416,   465,   938,  1573,    13,\n",
      "         12622, 41379,   293,   373,    11,   287,  1109,    11,  5033,   262,\n",
      "           582,   286,   262,  2589,   438,   292,  3619,  2241,    11,   530,\n",
      "          1244,  1234,   340,    11,   550,   587,   262,   582,   286,   262,\n",
      "          1711,    13,   383,  7099,  6802,   373,   531,   284,   423,  7042,\n",
      "          2241,   379,   616,  1545,   338,  3625,    11,   290,   314, 14028,\n",
      "           611,   257,   256, 11912,   286, 35394,   739, 10724,   262,  6846,\n",
      "           338, 11428,   450,    67,  3299,    13,   887,   645,   438,  1640,\n",
      "           340,   373,   407, 10597,   706,   326,  1785,   326,   262,  4808,\n",
      "         13698, 10322,  6532,    62,  8263,    12,  9649,   550,  9258,   284,\n",
      "          3359,   511,   366,  8642,   521,   829,   526,   198,   198,    40,\n",
      "          2900,   284,  9074,    13,   402,   271, 10899,    11,   508,   550,\n",
      "         18459,  1068,   284,  1577,   257, 23844,   286,  7543,   284,   607,\n",
      "           599,  6321,   287,   262, 17423,    12,  3823,    13,   198,   198,\n",
      "             1,  5195,  4808, 10134,    62,   339,   442, 17758, 12036,  1701,\n",
      "           314,  1965, 25891,    13,   198,   198,  3347,  4376,   607, 26928,\n",
      "           351,   257,  9254,   286,   922,    12, 17047,  8167,  5975,    13,\n",
      "           198,   198,     1,  5812,    11,   339,  1595,   470,  4808, 14150,\n",
      "            62,   284,   783,    11,   345,   760,    26,   290,   314,   765,\n",
      "           683,   284,  2883,  2241,   553,   673,   531,  2407,  2391,    13,\n",
      "           198,   198,    40,  3114,   546,   262, 40894,  2330,    12,  6839,\n",
      "         11978,  2119,    11,   351,   663,  4808, 44769,  8270,    12,   332,\n",
      "           660,    62,   410,  1386, 20394,   262, 23755,   286,   262, 14005,\n",
      "          1801,  2093, 41160,    11,   290,   663, 45592,    12, 14792,  1613,\n",
      "          1424,   287, 19217, 24887, 13431,    13]])\n",
      "tensor([[   13,   198,   198,     1, 19242,   339,   442, 17758,   465,  5986,\n",
      "          1165,    30,   314,  4398,   470,  1775,   257,  2060,   530,   287,\n",
      "           262,  2156,   526,   198,   198,    32,  3731, 17979,   286, 32315,\n",
      "         12606,  9074,    13,   402,   271, 10899,   338,  1280,   954, 36368,\n",
      "            13,   366,  1026,   338,   465, 11441, 48740,    11,   345,   760,\n",
      "            13,   679,  1139,   484,   821,   407,  4197,   284,   423,   546,\n",
      "            26,   339,   338,  1908,   606,   477,  1497,  2845,   530,   438,\n",
      "          1820, 18560,   438,   392,   326,   314,   423,   284,  1394, 26148,\n",
      "           526,   198,   198,  6653, 11441, 48740,   438, 14295,   338, 48740,\n",
      "           546,   465,  5986,    30,  2011, 20136,   373,  3957,   588,   262,\n",
      "         26394,    12,   301,   971,    13,   314,   531, 10722,   292,  2280,\n",
      "           284,   616,  2583,   408,    25,   366,    40,  1276,  1107,   766,\n",
      "           534, 18560,    11,   345,   760,   526,   198,   198,  3347, 27846,\n",
      "           503,  2048,  4628, 24882,   379,   262,  8812,   558,   810,   607,\n",
      "          5229,    11, 21081,   782,   278,   287,   257, 14263,   276,  5118,\n",
      "            11,   550,  6578,   257, 24518,   290,  7428,   262,  3394, 20096,\n",
      "         39047,   338,  1182,  1022,   465, 14475,    13,   198,   198,     1,\n",
      "          5779,    11,  1282,   981,   339,   338,   407,  2045,   553,   673,\n",
      "           531,    11,   351,   257,  6487,   326,  3088,   284,  7808,   607,\n",
      "         10927,  1108,    26,   290,   314,  3940,   607,  1022,   262, 30623,\n",
      "          2295, 49406,   286,   262,  6899,    11,   290,   510,   262,  3094,\n",
      "         16046,   351,  1059,   430,    12,    66, 12375,   299, 20896,    82,\n",
      "         24357,  1871, 12734,   379,  1123,  9581,    13,   198,   198,   818,\n",
      "           262,  5391,    76,   395,  5228,   286,   607,   275,  2778, 10840,\n",
      "            11, 10371,   257,  1534,  4241,   286, 19217,   290, 18876,  5563,\n",
      "            11,  9174,   530,   286,   262,  5385],\n",
      "        [10197,   832,   262, 46475,   286, 18113,   544,   338, 10953,   314,\n",
      "          2936,  1498,   284,  1986,   262,  1109,   351,  1602, 11227,   414,\n",
      "            13, 23676,  3619,   402,   271, 10899,     0,   383,  1466,   550,\n",
      "           925,   683,   438,   270,   373, 15830,   326,   484,   815, 25722,\n",
      "           683,    13,  9754,   465,   898,  1714,  7380, 30090,   547,  2982,\n",
      "            11,   290,   287,   465,   898,  3292,  8941,   257,  4636, 28582,\n",
      "            13, 18612, 35394,    30,  8673,    13,  1002,   340,   547,    11,\n",
      "           262, 15393,   286,   262,  5977,   373, 29178,  3474,   416,  1310,\n",
      "         40559, 11959,  1636,    11,   508,    11,   287,   477,   922,  4562,\n",
      "            11,  3181,   503,   287,   262, 37090,   257,   845, 22665,   366,\n",
      "           672,   270,  2838,     1,   319,  3619,   438,   505,   286,   883,\n",
      "           905,    88,  6685, 42070,   351,  4738,  6276,   871,   326,   314,\n",
      "           423,  2982,   357,    40,  1839,   470,   910,   416,  4150,     8,\n",
      "          3688,   284,   402,   271, 10899,   338, 12036,    13,   843,   523,\n",
      "           438, 14363, 10568,   852,  5729, 11331, 18893,   540,   438,  1169,\n",
      "          5114, 11835,  3724,   503,    11,   290,    11,   355,  9074,    13,\n",
      "           536,  5469,   550, 11001,    11,   262,  2756,   286,   366,    38,\n",
      "           271, 10899,    82,     1,  1816,   510,    13,   198,   198,  1026,\n",
      "           373,   407, 10597,  1115,   812,  1568,   326,    11,   287,   262,\n",
      "          1781,   286,   257,  1178,  2745,     6,  4686,  1359,   319,   262,\n",
      "         34686, 41976,    11,   340,  6451,  5091,   284,   502,   284,  4240,\n",
      "          1521,   402,   271, 10899,   550,  1813,   510,   465, 12036,    13,\n",
      "          1550, 14580,    11,   340,  1107,   373,   257, 29850,  1917,    13,\n",
      "          1675, 24456,   465,  3656,   561,   423,   587,  1165,  2562,   438,\n",
      "         14363,  3148,  1650,  1010,   550,   587,  6699,   262,  1540,   558,\n",
      "           286,  2282,   326,  9074,    13,   402]]) tensor([[  198,   198,     1, 19242,   339,   442, 17758,   465,  5986,  1165,\n",
      "            30,   314,  4398,   470,  1775,   257,  2060,   530,   287,   262,\n",
      "          2156,   526,   198,   198,    32,  3731, 17979,   286, 32315, 12606,\n",
      "          9074,    13,   402,   271, 10899,   338,  1280,   954, 36368,    13,\n",
      "           366,  1026,   338,   465, 11441, 48740,    11,   345,   760,    13,\n",
      "           679,  1139,   484,   821,   407,  4197,   284,   423,   546,    26,\n",
      "           339,   338,  1908,   606,   477,  1497,  2845,   530,   438,  1820,\n",
      "         18560,   438,   392,   326,   314,   423,   284,  1394, 26148,   526,\n",
      "           198,   198,  6653, 11441, 48740,   438, 14295,   338, 48740,   546,\n",
      "           465,  5986,    30,  2011, 20136,   373,  3957,   588,   262, 26394,\n",
      "            12,   301,   971,    13,   314,   531, 10722,   292,  2280,   284,\n",
      "           616,  2583,   408,    25,   366,    40,  1276,  1107,   766,   534,\n",
      "         18560,    11,   345,   760,   526,   198,   198,  3347, 27846,   503,\n",
      "          2048,  4628, 24882,   379,   262,  8812,   558,   810,   607,  5229,\n",
      "            11, 21081,   782,   278,   287,   257, 14263,   276,  5118,    11,\n",
      "           550,  6578,   257, 24518,   290,  7428,   262,  3394, 20096, 39047,\n",
      "           338,  1182,  1022,   465, 14475,    13,   198,   198,     1,  5779,\n",
      "            11,  1282,   981,   339,   338,   407,  2045,   553,   673,   531,\n",
      "            11,   351,   257,  6487,   326,  3088,   284,  7808,   607, 10927,\n",
      "          1108,    26,   290,   314,  3940,   607,  1022,   262, 30623,  2295,\n",
      "         49406,   286,   262,  6899,    11,   290,   510,   262,  3094, 16046,\n",
      "           351,  1059,   430,    12,    66, 12375,   299, 20896,    82, 24357,\n",
      "          1871, 12734,   379,  1123,  9581,    13,   198,   198,   818,   262,\n",
      "          5391,    76,   395,  5228,   286,   607,   275,  2778, 10840,    11,\n",
      "         10371,   257,  1534,  4241,   286, 19217,   290, 18876,  5563,    11,\n",
      "          9174,   530,   286,   262,  5385, 41186],\n",
      "        [  832,   262, 46475,   286, 18113,   544,   338, 10953,   314,  2936,\n",
      "          1498,   284,  1986,   262,  1109,   351,  1602, 11227,   414,    13,\n",
      "         23676,  3619,   402,   271, 10899,     0,   383,  1466,   550,   925,\n",
      "           683,   438,   270,   373, 15830,   326,   484,   815, 25722,   683,\n",
      "            13,  9754,   465,   898,  1714,  7380, 30090,   547,  2982,    11,\n",
      "           290,   287,   465,   898,  3292,  8941,   257,  4636, 28582,    13,\n",
      "         18612, 35394,    30,  8673,    13,  1002,   340,   547,    11,   262,\n",
      "         15393,   286,   262,  5977,   373, 29178,  3474,   416,  1310, 40559,\n",
      "         11959,  1636,    11,   508,    11,   287,   477,   922,  4562,    11,\n",
      "          3181,   503,   287,   262, 37090,   257,   845, 22665,   366,   672,\n",
      "           270,  2838,     1,   319,  3619,   438,   505,   286,   883,   905,\n",
      "            88,  6685, 42070,   351,  4738,  6276,   871,   326,   314,   423,\n",
      "          2982,   357,    40,  1839,   470,   910,   416,  4150,     8,  3688,\n",
      "           284,   402,   271, 10899,   338, 12036,    13,   843,   523,   438,\n",
      "         14363, 10568,   852,  5729, 11331, 18893,   540,   438,  1169,  5114,\n",
      "         11835,  3724,   503,    11,   290,    11,   355,  9074,    13,   536,\n",
      "          5469,   550, 11001,    11,   262,  2756,   286,   366,    38,   271,\n",
      "         10899,    82,     1,  1816,   510,    13,   198,   198,  1026,   373,\n",
      "           407, 10597,  1115,   812,  1568,   326,    11,   287,   262,  1781,\n",
      "           286,   257,  1178,  2745,     6,  4686,  1359,   319,   262, 34686,\n",
      "         41976,    11,   340,  6451,  5091,   284,   502,   284,  4240,  1521,\n",
      "           402,   271, 10899,   550,  1813,   510,   465, 12036,    13,  1550,\n",
      "         14580,    11,   340,  1107,   373,   257, 29850,  1917,    13,  1675,\n",
      "         24456,   465,  3656,   561,   423,   587,  1165,  2562,   438, 14363,\n",
      "          3148,  1650,  1010,   550,   587,  6699,   262,  1540,   558,   286,\n",
      "          2282,   326,  9074,    13,   402,   271]])\n",
      "tensor([[ 1459,   714,  1239,   423,  4499,   326, 18680,   510,    12,  5532,\n",
      "         14000,    13,   764,   764,   764,   198,   198,     1,    40,  2900,\n",
      "           736,   284,   616,   670,    11,   290,  1816,   319, 39136,   278,\n",
      "           290,   285,  4185,  1359,    26,   788,   314,  3114,   379,   262,\n",
      "         50085,   757,    13,   314,  2497,   326,    11,   618,   520,  5493,\n",
      "          8104,   287,   262,   717, 14000,    11,   339,  2993,   655,   644,\n",
      "           262,   886,   561,   307,    13,   679,   550, 17273,   465,  2426,\n",
      "            11, 19233,   340,    11, 11027,   515,   340,    13,  1649,   550,\n",
      "           314,  1760,   326,   351,   597,   286,   616,  1243,    30,  1119,\n",
      "          8020,   470,   587,  4642,   286,   502,   438,    40,   550,   655,\n",
      "          8197,   606,    13,   764,   764,   764,   198,   198,     1,    39,\n",
      "           648,   340,    11,  8759,  2763,    11,   351,   326,  1986,  4964,\n",
      "           502,   314,  3521,   470,   466,  1194, 14000,    13,   383,  8631,\n",
      "          3872,   373,    11,   314,  1422,   470,   760,   810,   284,  1234,\n",
      "           340,   438,    62,    40,   550,  1239,  1900, 44807,  5514,    11,\n",
      "           351,   616,  1650,  1010,   290,   616,  1171,    11,   257,   905,\n",
      "            88, 22870,   286,  9568,  5017,   510,   262,  1109,   438,    40,\n",
      "           655,  9617,  7521,   656,   511,  6698,    13,   764,   764,   764,\n",
      "          3894,    11,  7521,   373,   262,   530,  7090,   883,  2636,  2951,\n",
      "           714,   766,   832,   438,  3826,  3892,   284,   262,  2006, 20212,\n",
      "         19369, 14638,    13,  2094,   470,   345,   760,   703,    11,   287,\n",
      "          3375,   257,  3215,  3303,    11,   772,  6562,  1473,    11,   530,\n",
      "          1139,  2063,   262,   640,   407,   644,   530,  3382,   284,   475,\n",
      "           644,   530,   460,    30,  3894,   438,  5562,   373,   262,   835,\n",
      "           314, 13055,    26,   290,   355,   339,  3830,   612,   290,  7342,\n",
      "           502,    11,   262,  1517,   484,  1444],\n",
      "        [  271, 10899,   550,   366,  7109, 14655,   683,   866,   526,  1114,\n",
      "          9074,    13,   402,   271, 10899,   438,   292,   884,   438, 18108,\n",
      "           407, 11196, 10597,  3016,   257,   614,   706,  3619,   338, 10568,\n",
      "           550,   587,  2077,    13,   632,  1244,   307,   326,   339,   550,\n",
      "          6405,   607,   438, 20777,   339,  8288,   465, 10152,   438, 13893,\n",
      "           339,  1422,   470,   765,   284,   467,   319, 12036,    26,   475,\n",
      "           340,   561,   423,   587,  1327,   284,  5879,   326,   339,   550,\n",
      "          1813,   510,   465, 12036,   780,   339,   550,  6405,   607,    13,\n",
      "           198,   198,  5189,  1781,    11,   611,   673,   550,   407, 17901,\n",
      "           683,   866,    11,   673,   550,  8603,    11,   355,  4544,  9325,\n",
      "           701, 42397,    11,  4054,   284,   366, 26282,   683,   510,     1,\n",
      "           438,  7091,   550,   407,  2957,   683,   736,   284,   262,  1396,\n",
      "           417,    13,  1675,  1234,   262, 14093,   656,   465,  1021,   757,\n",
      "           438, 10919,   257,   410,  5040,   329,   257,  3656,     0,   887,\n",
      "          9074,    13,   402,   271, 10899,  4120,   284,   423,   595,    67,\n",
      "          1328,   340,   438,   392,   314,  2936,   340,  1244,   307,  3499,\n",
      "           284,  1064,   503,  1521,    13,   198,   198,   464,   748,   586,\n",
      "           652,  1204,   286,   262, 34686, 41976, 37733,  2346,   284,   884,\n",
      "         14177,  8233,  1020,  5768,    26,   290,  1719,    11,   319,   616,\n",
      "           835,   284, 22489, 40089,    11,  4978,   257, 19350,   286,  3619,\n",
      "           338,  3652,   436,    81,  5286,  8812,  2114,  1022,   262,   279,\n",
      "          1127,    11,   314,   550,  3589, 28068,   294,  1555,   262,  1306,\n",
      "          1110,    13,   198,   198,    40,  1043,   262,  3155,   379,  8887,\n",
      "         11061,   511, 18057,    12,    83,  6037,    26,   290,  9074,    13,\n",
      "           402,   271, 10899,   338,  7062,   373,   523,  2429,   498,   326,\n",
      "            11,   287,   262, 29543,  2745,    11]]) tensor([[  714,  1239,   423,  4499,   326, 18680,   510,    12,  5532, 14000,\n",
      "            13,   764,   764,   764,   198,   198,     1,    40,  2900,   736,\n",
      "           284,   616,   670,    11,   290,  1816,   319, 39136,   278,   290,\n",
      "           285,  4185,  1359,    26,   788,   314,  3114,   379,   262, 50085,\n",
      "           757,    13,   314,  2497,   326,    11,   618,   520,  5493,  8104,\n",
      "           287,   262,   717, 14000,    11,   339,  2993,   655,   644,   262,\n",
      "           886,   561,   307,    13,   679,   550, 17273,   465,  2426,    11,\n",
      "         19233,   340,    11, 11027,   515,   340,    13,  1649,   550,   314,\n",
      "          1760,   326,   351,   597,   286,   616,  1243,    30,  1119,  8020,\n",
      "           470,   587,  4642,   286,   502,   438,    40,   550,   655,  8197,\n",
      "           606,    13,   764,   764,   764,   198,   198,     1,    39,   648,\n",
      "           340,    11,  8759,  2763,    11,   351,   326,  1986,  4964,   502,\n",
      "           314,  3521,   470,   466,  1194, 14000,    13,   383,  8631,  3872,\n",
      "           373,    11,   314,  1422,   470,   760,   810,   284,  1234,   340,\n",
      "           438,    62,    40,   550,  1239,  1900, 44807,  5514,    11,   351,\n",
      "           616,  1650,  1010,   290,   616,  1171,    11,   257,   905,    88,\n",
      "         22870,   286,  9568,  5017,   510,   262,  1109,   438,    40,   655,\n",
      "          9617,  7521,   656,   511,  6698,    13,   764,   764,   764,  3894,\n",
      "            11,  7521,   373,   262,   530,  7090,   883,  2636,  2951,   714,\n",
      "           766,   832,   438,  3826,  3892,   284,   262,  2006, 20212, 19369,\n",
      "         14638,    13,  2094,   470,   345,   760,   703,    11,   287,  3375,\n",
      "           257,  3215,  3303,    11,   772,  6562,  1473,    11,   530,  1139,\n",
      "          2063,   262,   640,   407,   644,   530,  3382,   284,   475,   644,\n",
      "           530,   460,    30,  3894,   438,  5562,   373,   262,   835,   314,\n",
      "         13055,    26,   290,   355,   339,  3830,   612,   290,  7342,   502,\n",
      "            11,   262,  1517,   484,  1444,   616],\n",
      "        [10899,   550,   366,  7109, 14655,   683,   866,   526,  1114,  9074,\n",
      "            13,   402,   271, 10899,   438,   292,   884,   438, 18108,   407,\n",
      "         11196, 10597,  3016,   257,   614,   706,  3619,   338, 10568,   550,\n",
      "           587,  2077,    13,   632,  1244,   307,   326,   339,   550,  6405,\n",
      "           607,   438, 20777,   339,  8288,   465, 10152,   438, 13893,   339,\n",
      "          1422,   470,   765,   284,   467,   319, 12036,    26,   475,   340,\n",
      "           561,   423,   587,  1327,   284,  5879,   326,   339,   550,  1813,\n",
      "           510,   465, 12036,   780,   339,   550,  6405,   607,    13,   198,\n",
      "           198,  5189,  1781,    11,   611,   673,   550,   407, 17901,   683,\n",
      "           866,    11,   673,   550,  8603,    11,   355,  4544,  9325,   701,\n",
      "         42397,    11,  4054,   284,   366, 26282,   683,   510,     1,   438,\n",
      "          7091,   550,   407,  2957,   683,   736,   284,   262,  1396,   417,\n",
      "            13,  1675,  1234,   262, 14093,   656,   465,  1021,   757,   438,\n",
      "         10919,   257,   410,  5040,   329,   257,  3656,     0,   887,  9074,\n",
      "            13,   402,   271, 10899,  4120,   284,   423,   595,    67,  1328,\n",
      "           340,   438,   392,   314,  2936,   340,  1244,   307,  3499,   284,\n",
      "          1064,   503,  1521,    13,   198,   198,   464,   748,   586,   652,\n",
      "          1204,   286,   262, 34686, 41976, 37733,  2346,   284,   884, 14177,\n",
      "          8233,  1020,  5768,    26,   290,  1719,    11,   319,   616,   835,\n",
      "           284, 22489, 40089,    11,  4978,   257, 19350,   286,  3619,   338,\n",
      "          3652,   436,    81,  5286,  8812,  2114,  1022,   262,   279,  1127,\n",
      "            11,   314,   550,  3589, 28068,   294,  1555,   262,  1306,  1110,\n",
      "            13,   198,   198,    40,  1043,   262,  3155,   379,  8887, 11061,\n",
      "           511, 18057,    12,    83,  6037,    26,   290,  9074,    13,   402,\n",
      "           271, 10899,   338,  7062,   373,   523,  2429,   498,   326,    11,\n",
      "           287,   262, 29543,  2745,    11,   314]])\n",
      "tensor([[ 1092,   517,   621,   611,   314,  1549,  1239, 12615,   257, 14093,\n",
      "           526,   198,   198,  1870,   465,  8216,  1297,   502,   287,   257,\n",
      "          7644,   326,   339,  1239,  1807,   286,  1997,  2073,    13,   198,\n",
      "           198,    40,  3888,  1497,    11, 43045, 21100,   416,   616, 10059,\n",
      "          9412,    26,   290,   355,   314,  2900,    11,   616,  4151,  3214,\n",
      "           319,   257,  1402,  4286,  2029,   262, 24818,   417,    12, 12239,\n",
      "           438,  1169,   691,  2134,  7163,   262,  8631, 26210,  3425,  9417,\n",
      "           286,   262,  2119,    13,   198,   198,     1,  5812,    11,   416,\n",
      "           449,   659,  2474,   314,   531,    13,   198,   198,  1026,   373,\n",
      "           257, 17548,   286,   257, 50085,   438,   272,  1468, 10032, 50085,\n",
      "            11,  5055,   287,   262,  6290,   739,   257,  3355,    13,   198,\n",
      "           198,     1,  3886,   449,   659,   438,    64,   520,  5493,  2474,\n",
      "           314, 16896,    13,   198,   198,  1544,   373, 10574,    26,   475,\n",
      "           314,  2936,   683,  1969,  2157,   502,    11, 12704,   257,  1310,\n",
      "          2952,    13,   198,   198,     1,  2061,   257,  4240,     0, 14446,\n",
      "           351,   257,  8667,  3951,   438,  4360,   319, 45697, 19369,    13,\n",
      "           921,  9670, 28022,    11,   810,   750,   345,   651,   340,  1701,\n",
      "           198,   198,  1544,  9373,  6364,    25,   366, 27034,    13,   520,\n",
      "          5493,  2921,   340,   284,   502,   526,   198,   198,     1, 10910,\n",
      "           438,    40,  1422,   470,   760,   345,   772,  2993,   262,   520,\n",
      "          5493,    82,    13,   679,   373,   884,   281,  1167,  2588,   856,\n",
      "           607,  2781,   526,   198,   198,     1,    40,  1422,   470,   438,\n",
      "            83,   359,   706,    13,   764,   764,   764,  1375,  1908,   329,\n",
      "           502,   284,  7521,   683,   618,   339,   373,  2636,   526,   198,\n",
      "           198,     1,  2215,   339,   373,  2636,    30,   921,  1701,   198,\n",
      "           198,    40,  1276,   423,  1309,   257],\n",
      "        [ 1310,  1165,   881, 40642,   972,  6654,   832,   616,  5975,    11,\n",
      "           329,   339,  9373,   351,   257,  1207,  8344,   803,  6487,    25,\n",
      "           366,  5297,   438,  7091,   338,   281, 12659,  2829,  1122,    11,\n",
      "           345,   760,    11,  9074,    13,   520,  5493,    13,  2332,   691,\n",
      "          2126,   373,   284,   423,   683,  1760,   416,   257, 38378, 34537,\n",
      "           438,   993,    11,  3595,   520,  5493,     0,  1375,  1807,   340,\n",
      "           262,  1654,   301,   835,   286, 46431,   465, 27951,   438,  1659,\n",
      "         10833,   340,   319,   257,  1308, 27461,  1171,    13,   843,   379,\n",
      "           262,  2589,   314,   373,  4808,  1169,    62, 38378, 34537,   526,\n",
      "           198,   198,     1, 10910,    11,  3595,   520,  5493,   438,   292,\n",
      "           345,   910,    13,  8920,  4808,  5562,    62,   465,  2106,  1701,\n",
      "           198,   198,     1,  2504,   373,   465,  2106,    13,  1375,  4762,\n",
      "           287,   683,    11, 26996,   798,   287,   683,   438,   273,  1807,\n",
      "           673,   750,    13,   887,   673,  3521,   470,  6842,   407,   284,\n",
      "           423,   477,   262,  8263,    12,  9649,   351,   607,    13,  1375,\n",
      "          3521,   470,  6842,   262,  1109,   326,    11,   319,  1401,    77,\n",
      "          3929,  1528,    11,   530,   714,  1464,   651,  1474,  1576,   284,\n",
      "           766,   465,  5986,    13, 23676,  2415,     0,  1375,   338,   655,\n",
      "           257, 24225, 39136,   278,   329,   584, 21441,    13,   520,  5493,\n",
      "           318,   262,   691,  2187,   314,  1683,  2993,   526,   198,   198,\n",
      "             1,  1639,  1683,  2993,    30,   887,   345,   655,   531,   438,\n",
      "             1,   198,   198,    38,   271, 10899,   550,   257, 11040,  8212,\n",
      "           287,   465,  2951,    13,   198,   198,     1,  5812,    11,   314,\n",
      "          2993,   683,    11,   290,   339,  2993,   502,   438,  8807,   340,\n",
      "          3022,   706,   339,   373,  2636,   526,   198,   198,    40,  5710,\n",
      "           616,  3809, 43045,    13,   366,  2215]]) tensor([[  517,   621,   611,   314,  1549,  1239, 12615,   257, 14093,   526,\n",
      "           198,   198,  1870,   465,  8216,  1297,   502,   287,   257,  7644,\n",
      "           326,   339,  1239,  1807,   286,  1997,  2073,    13,   198,   198,\n",
      "            40,  3888,  1497,    11, 43045, 21100,   416,   616, 10059,  9412,\n",
      "            26,   290,   355,   314,  2900,    11,   616,  4151,  3214,   319,\n",
      "           257,  1402,  4286,  2029,   262, 24818,   417,    12, 12239,   438,\n",
      "          1169,   691,  2134,  7163,   262,  8631, 26210,  3425,  9417,   286,\n",
      "           262,  2119,    13,   198,   198,     1,  5812,    11,   416,   449,\n",
      "           659,  2474,   314,   531,    13,   198,   198,  1026,   373,   257,\n",
      "         17548,   286,   257, 50085,   438,   272,  1468, 10032, 50085,    11,\n",
      "          5055,   287,   262,  6290,   739,   257,  3355,    13,   198,   198,\n",
      "             1,  3886,   449,   659,   438,    64,   520,  5493,  2474,   314,\n",
      "         16896,    13,   198,   198,  1544,   373, 10574,    26,   475,   314,\n",
      "          2936,   683,  1969,  2157,   502,    11, 12704,   257,  1310,  2952,\n",
      "            13,   198,   198,     1,  2061,   257,  4240,     0, 14446,   351,\n",
      "           257,  8667,  3951,   438,  4360,   319, 45697, 19369,    13,   921,\n",
      "          9670, 28022,    11,   810,   750,   345,   651,   340,  1701,   198,\n",
      "           198,  1544,  9373,  6364,    25,   366, 27034,    13,   520,  5493,\n",
      "          2921,   340,   284,   502,   526,   198,   198,     1, 10910,   438,\n",
      "            40,  1422,   470,   760,   345,   772,  2993,   262,   520,  5493,\n",
      "            82,    13,   679,   373,   884,   281,  1167,  2588,   856,   607,\n",
      "          2781,   526,   198,   198,     1,    40,  1422,   470,   438,    83,\n",
      "           359,   706,    13,   764,   764,   764,  1375,  1908,   329,   502,\n",
      "           284,  7521,   683,   618,   339,   373,  2636,   526,   198,   198,\n",
      "             1,  2215,   339,   373,  2636,    30,   921,  1701,   198,   198,\n",
      "            40,  1276,   423,  1309,   257,  1310],\n",
      "        [ 1165,   881, 40642,   972,  6654,   832,   616,  5975,    11,   329,\n",
      "           339,  9373,   351,   257,  1207,  8344,   803,  6487,    25,   366,\n",
      "          5297,   438,  7091,   338,   281, 12659,  2829,  1122,    11,   345,\n",
      "           760,    11,  9074,    13,   520,  5493,    13,  2332,   691,  2126,\n",
      "           373,   284,   423,   683,  1760,   416,   257, 38378, 34537,   438,\n",
      "           993,    11,  3595,   520,  5493,     0,  1375,  1807,   340,   262,\n",
      "          1654,   301,   835,   286, 46431,   465, 27951,   438,  1659, 10833,\n",
      "           340,   319,   257,  1308, 27461,  1171,    13,   843,   379,   262,\n",
      "          2589,   314,   373,  4808,  1169,    62, 38378, 34537,   526,   198,\n",
      "           198,     1, 10910,    11,  3595,   520,  5493,   438,   292,   345,\n",
      "           910,    13,  8920,  4808,  5562,    62,   465,  2106,  1701,   198,\n",
      "           198,     1,  2504,   373,   465,  2106,    13,  1375,  4762,   287,\n",
      "           683,    11, 26996,   798,   287,   683,   438,   273,  1807,   673,\n",
      "           750,    13,   887,   673,  3521,   470,  6842,   407,   284,   423,\n",
      "           477,   262,  8263,    12,  9649,   351,   607,    13,  1375,  3521,\n",
      "           470,  6842,   262,  1109,   326,    11,   319,  1401,    77,  3929,\n",
      "          1528,    11,   530,   714,  1464,   651,  1474,  1576,   284,   766,\n",
      "           465,  5986,    13, 23676,  2415,     0,  1375,   338,   655,   257,\n",
      "         24225, 39136,   278,   329,   584, 21441,    13,   520,  5493,   318,\n",
      "           262,   691,  2187,   314,  1683,  2993,   526,   198,   198,     1,\n",
      "          1639,  1683,  2993,    30,   887,   345,   655,   531,   438,     1,\n",
      "           198,   198,    38,   271, 10899,   550,   257, 11040,  8212,   287,\n",
      "           465,  2951,    13,   198,   198,     1,  5812,    11,   314,  2993,\n",
      "           683,    11,   290,   339,  2993,   502,   438,  8807,   340,  3022,\n",
      "           706,   339,   373,  2636,   526,   198,   198,    40,  5710,   616,\n",
      "          3809, 43045,    13,   366,  2215,   673]])\n",
      "tensor([[22645,    11,   465, 10904,  4252,  6236,   429, 25839,  9230,   808,\n",
      "           276,   416,   257,  8212,   326, 13663,   262,  9040,   286,   257,\n",
      "          2116,    12, 10414,   738,   285, 23968,  4891,    11,   314,  2936,\n",
      "           284,   644,   257,  4922,   339,   550,   262,   976,  3081,   355,\n",
      "           465,  5986,   438,  1169,  3081,   286,  2045,  1190,  4119,    81,\n",
      "           621,   339,   373,    13,   198,   198,  6653,  3656, 27846,   379,\n",
      "           683,  1207,  8344,   803,   306,    11,   475,   465,  2951, 21650,\n",
      "          1613,   607,   284,   262, 18560,    13,   198,   198,     1,  5246,\n",
      "            13,  8759,  2763,  2227,   284,   766,   340,   553,   673,  2540,\n",
      "            11,   355,   611,  2859,  3500,  5223,    13,   679, 28271,   465,\n",
      "         12450,    11,   991, 16755,    13,   198,   198,     1,  5812,    11,\n",
      "          8759,  2763,  1043,   502,   503,   890,  2084,   553,   339,   531,\n",
      "         15376,    26,   788,    11,  6427,   465,  3211,   832,  6164,    25,\n",
      "           366, 16773,   290,   766,   262,  1334,   286,   262,  2156,   526,\n",
      "           198,   198,  1544,  3751,   340,   284,   502,   351,   257,  1611,\n",
      "           286, 24354, 20154, 11293,    25,   262,  7837,    12,  9649,    11,\n",
      "           262,  5486,    12,    83, 29080,    11,   262,  6576,    12,   565,\n",
      "           418,  1039,    11,   262,  4057,  2655,    12,  8439,   274,   438,\n",
      "           439,   262,  3716,  7106,  6637,   286,   262, 45172,   338,  5928,\n",
      "          3773,    13,   843,  8797,   616,  4240,  3432,   262,  2938, 17547,\n",
      "           339,   531,    11,  9644,   503,   465,  7721,   257,  1310,    25,\n",
      "           366,  5297,    11,   314,  1107,   836,   470,   766,   703,   661,\n",
      "          6687,   284,  2107,  1231,   326,   526,   198,   198,  5779,   438,\n",
      "           270,   373,   655,   262,   886,   530,  1244,   423,  1674, 15898,\n",
      "           329,   683,    13,  5514,   339,   373,    11,   832,   340,   477,\n",
      "           290,   287, 15275,   286,   340,   477],\n",
      "        [  286,  1762,    30,  2011, 29483,  2540,   284,   467,   257,  1310,\n",
      "          4295,   438,    40,  2936, 10927,   290,  8627,    13,   198,   198,\n",
      "             1,  7454,    11,   618,   314,  3114,   510,    11,   314,  3947,\n",
      "           284,   766,   257,  8212,  2157,   465,  1969, 12768,   680, 21213,\n",
      "           438,   292,   611,   339,   550,   262,  3200,    11,   290,   547,\n",
      "         28297,  2241,   416,  4769,   340,   736,   422,   502,    13,  1320,\n",
      "         41851,   515,   502,   991,   517,    13,   383,  3200,    30,  4162,\n",
      "            11,   314,   550,   257,  3200,  2861,  8208,   286,   465,     0,\n",
      "           314, 37901,   379,   262, 21978, 44896,    11,   290,  3088,   617,\n",
      "           286,   616, 49025,  5330, 15910,    13,   887,   484,  4054,   502,\n",
      "            11,   484,  1067, 11137,    13,   314,  2497,   326,   339,  2492,\n",
      "           470,  4964,   262,   905,    88, 10340,   438,    40,  3521,   470,\n",
      "         11786,   465,  3241,    26,   339,   655,  4030,   465,  2951,   319,\n",
      "           262,  1327, 22674,  1022,    13,  5845,   547,   262,  3392,   314,\n",
      "           550,  1464,   427,   343,  9091,    11,   393,  5017,   510,   351,\n",
      "           617,  9105,  7521,    13,   843,   703,   339,  2497,   832,   616,\n",
      "          7363,     0,   198,   198,     1,    40,  3114,   510,   757,    11,\n",
      "           290,  4978,  6504,   286,   326, 17548,   286,   262, 50085, 10938,\n",
      "           319,   262,  3355,  1474,   465,  3996,    13,  2399,  3656,  1297,\n",
      "           502, 20875,   340,   373,   262,   938,  1517,   339,   550,  1760,\n",
      "           438,  3137,   257,  3465,  2077,   351,   257, 17275,  1021,    11,\n",
      "           618,   339,   373,   866,   287,  6245,   684, 10695, 20222,   422,\n",
      "           257,  2180,  2612,  1368,    13,  2329,   257,  3465,     0,   887,\n",
      "           340,  4952,   465,  2187,  2106,    13,  1318,   389,   812,   286,\n",
      "          5827, 40987,   913, 30802,   287,   790,  1627,    13,   317,   582,\n",
      "           508,   550,  1509,   388,   351,   262]]) tensor([[   11,   465, 10904,  4252,  6236,   429, 25839,  9230,   808,   276,\n",
      "           416,   257,  8212,   326, 13663,   262,  9040,   286,   257,  2116,\n",
      "            12, 10414,   738,   285, 23968,  4891,    11,   314,  2936,   284,\n",
      "           644,   257,  4922,   339,   550,   262,   976,  3081,   355,   465,\n",
      "          5986,   438,  1169,  3081,   286,  2045,  1190,  4119,    81,   621,\n",
      "           339,   373,    13,   198,   198,  6653,  3656, 27846,   379,   683,\n",
      "          1207,  8344,   803,   306,    11,   475,   465,  2951, 21650,  1613,\n",
      "           607,   284,   262, 18560,    13,   198,   198,     1,  5246,    13,\n",
      "          8759,  2763,  2227,   284,   766,   340,   553,   673,  2540,    11,\n",
      "           355,   611,  2859,  3500,  5223,    13,   679, 28271,   465, 12450,\n",
      "            11,   991, 16755,    13,   198,   198,     1,  5812,    11,  8759,\n",
      "          2763,  1043,   502,   503,   890,  2084,   553,   339,   531, 15376,\n",
      "            26,   788,    11,  6427,   465,  3211,   832,  6164,    25,   366,\n",
      "         16773,   290,   766,   262,  1334,   286,   262,  2156,   526,   198,\n",
      "           198,  1544,  3751,   340,   284,   502,   351,   257,  1611,   286,\n",
      "         24354, 20154, 11293,    25,   262,  7837,    12,  9649,    11,   262,\n",
      "          5486,    12,    83, 29080,    11,   262,  6576,    12,   565,   418,\n",
      "          1039,    11,   262,  4057,  2655,    12,  8439,   274,   438,   439,\n",
      "           262,  3716,  7106,  6637,   286,   262, 45172,   338,  5928,  3773,\n",
      "            13,   843,  8797,   616,  4240,  3432,   262,  2938, 17547,   339,\n",
      "           531,    11,  9644,   503,   465,  7721,   257,  1310,    25,   366,\n",
      "          5297,    11,   314,  1107,   836,   470,   766,   703,   661,  6687,\n",
      "           284,  2107,  1231,   326,   526,   198,   198,  5779,   438,   270,\n",
      "           373,   655,   262,   886,   530,  1244,   423,  1674, 15898,   329,\n",
      "           683,    13,  5514,   339,   373,    11,   832,   340,   477,   290,\n",
      "           287, 15275,   286,   340,   477,   438],\n",
      "        [ 1762,    30,  2011, 29483,  2540,   284,   467,   257,  1310,  4295,\n",
      "           438,    40,  2936, 10927,   290,  8627,    13,   198,   198,     1,\n",
      "          7454,    11,   618,   314,  3114,   510,    11,   314,  3947,   284,\n",
      "           766,   257,  8212,  2157,   465,  1969, 12768,   680, 21213,   438,\n",
      "           292,   611,   339,   550,   262,  3200,    11,   290,   547, 28297,\n",
      "          2241,   416,  4769,   340,   736,   422,   502,    13,  1320, 41851,\n",
      "           515,   502,   991,   517,    13,   383,  3200,    30,  4162,    11,\n",
      "           314,   550,   257,  3200,  2861,  8208,   286,   465,     0,   314,\n",
      "         37901,   379,   262, 21978, 44896,    11,   290,  3088,   617,   286,\n",
      "           616, 49025,  5330, 15910,    13,   887,   484,  4054,   502,    11,\n",
      "           484,  1067, 11137,    13,   314,  2497,   326,   339,  2492,   470,\n",
      "          4964,   262,   905,    88, 10340,   438,    40,  3521,   470, 11786,\n",
      "           465,  3241,    26,   339,   655,  4030,   465,  2951,   319,   262,\n",
      "          1327, 22674,  1022,    13,  5845,   547,   262,  3392,   314,   550,\n",
      "          1464,   427,   343,  9091,    11,   393,  5017,   510,   351,   617,\n",
      "          9105,  7521,    13,   843,   703,   339,  2497,   832,   616,  7363,\n",
      "             0,   198,   198,     1,    40,  3114,   510,   757,    11,   290,\n",
      "          4978,  6504,   286,   326, 17548,   286,   262, 50085, 10938,   319,\n",
      "           262,  3355,  1474,   465,  3996,    13,  2399,  3656,  1297,   502,\n",
      "         20875,   340,   373,   262,   938,  1517,   339,   550,  1760,   438,\n",
      "          3137,   257,  3465,  2077,   351,   257, 17275,  1021,    11,   618,\n",
      "           339,   373,   866,   287,  6245,   684, 10695, 20222,   422,   257,\n",
      "          2180,  2612,  1368,    13,  2329,   257,  3465,     0,   887,   340,\n",
      "          4952,   465,  2187,  2106,    13,  1318,   389,   812,   286,  5827,\n",
      "         40987,   913, 30802,   287,   790,  1627,    13,   317,   582,   508,\n",
      "           550,  1509,   388,   351,   262,  1459]])\n",
      "tensor([[  673,  1908,   329,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474,   198,   198,  1544,\n",
      "         13818,   757,    11,   290,  9617,   736,   465,  1182,   284,   804,\n",
      "           510,   379,   262, 17548,   286,   262, 50085,    13,   366,  1858,\n",
      "           547,  1528,   618,   314,  3521,   470,   804,   379,   326,  1517,\n",
      "           438, 24089,    77,   470,  1986,   340,    13,   887,   314,  4137,\n",
      "          3589,   284,  1234,   340,   994,    26,   290,   783,   340,   338,\n",
      "         30703,   502,   438,    66,  1522,   502,    13,  1320,   338,   262,\n",
      "          1738,  1521,   314,   836,   470, 45553,   903,   597,   517,    11,\n",
      "           616, 13674,  8759,  2763,    26,   393,  2138,   520,  5493,  2241,\n",
      "           318,   262,  1738,   526,   198,   198,  1890,   262,   717,   640,\n",
      "           616, 21696, 20136,   546,   616, 15185,  2900,   656,   257,  2726,\n",
      "          6227,   284,  1833,   683,  1365,    13,   198,   198,     1,    40,\n",
      "          4601,   345,  1549,  1560,   502,   703,   340,  3022,   553,   314,\n",
      "           531,    13,   198,   198,  1544,  6204,  2045,   510,   379,   262,\n",
      "         17548,    11,   290,   665, 24297,  1022,   465,  9353,   257, 17779,\n",
      "           339,   550, 11564,   284,  1657,    13, 24975,   339,  2900,  3812,\n",
      "           502,    13,   198,   198,     1,    40,  1549,  2138,   588,   284,\n",
      "          1560,   345,   438, 13893,   314,  1053,  1464,  9885,   345,   286,\n",
      "          2376, 26927,   616,   670,   526,   198,   198,    40,   925,   257,\n",
      "          1207,  8344,   803, 18342,    11,   543,   339,  2469,   265,  1572,\n",
      "           351,   257,   922,    12, 17047,  8167, 32545,    13,   198,   198,\n",
      "             1,  5812,    11,   314,  1422,   470,  1337,   257, 14787,   618,\n",
      "           314,  4762,   287,  3589,   438,   392,   783,   340,   338,   281,\n",
      "          2087,  9839,  1022,   514,  2474,   198],\n",
      "        [  438,   292,   339,   550,   587,   832,    11,   290,   287, 15275,\n",
      "           286,    11,   465,  5986,   438,   568, 22665,    11,   523, 23332,\n",
      "            11,   523,   595, 18052,    11,   326,   530,   890,   276,   284,\n",
      "          3960,   503,    25,   366,  3856, 44455,   351,   534, 24638,  2474,\n",
      "           355,  1752,   530,   550,   890,   276,   284,   910,    25,   366,\n",
      "          3856, 44455,   351,   534,   670,  2474,   198,   198,  1537,    11,\n",
      "           351,   262,  3960,   319,   616, 11914,    11,   616, 13669,  6989,\n",
      "           281, 10059,  2198,    13,   198,   198,     1,  1212,   318,   616,\n",
      "           898, 49451,   553,   339,   531,    11,  3756,   502,   656,   257,\n",
      "          3223,  8631,  2119,   379,   262,   886,   286,   262,   781,   273,\n",
      "           312,   410, 12523,    13,   632,   373,  6616,   290,  7586,   290,\n",
      "         11620,    88,    25,   645,   366, 34435,  8172,   645,   865,   291,\n",
      "            12,    64,    12,  1671,   330,    11,  4844,   286,   262,  1633,\n",
      "           286, 24380,   329, 20728,   287,   257,  4286, 10273,   438, 29370,\n",
      "           477,    11,   645,  1551,  1051,   286,  1683,  1719,   587,   973,\n",
      "           355,   257,  8034,    13,   198,   198,   464,  1109,  3181,  1363,\n",
      "           284,   502,   262,  4112,   957,  1483,   286,  3619,   338,  2270,\n",
      "           351,   465,  1468,  1204,    13,   198,   198,     1,  3987,   470,\n",
      "           345,  1683, 45553,   903,   351,  7521,   597,   517,  1701,   314,\n",
      "          1965,    11,   991,  2045,   546,   329,   257, 12854,   286,   884,\n",
      "          3842,    13,   198,   198,     1, 12295,   553,   339,   531, 11589,\n",
      "            13,   198,   198,     1,  5574,  1660,    12, 49903,   438,   273,\n",
      "          2123, 10813,  1701,   198,   198,  6653,  6563,  2951,  6348,  5391,\n",
      "            11,   290,   465, 25839,   279,  3021,   257,  1310,   739,   511,\n",
      "         22665,  4252, 10899,    13,   198,   198,     1, 12295,   892,   286,\n",
      "           340,    11,   616, 13674,  5891,   438]]) tensor([[ 1908,   329,   345,  1701,   198,   198,     1,  5297,   438, 37121,\n",
      "          1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683, 29178,\n",
      "          3474,   438,   392,   416,   502,  2474,   198,   198,  1544, 13818,\n",
      "           757,    11,   290,  9617,   736,   465,  1182,   284,   804,   510,\n",
      "           379,   262, 17548,   286,   262, 50085,    13,   366,  1858,   547,\n",
      "          1528,   618,   314,  3521,   470,   804,   379,   326,  1517,   438,\n",
      "         24089,    77,   470,  1986,   340,    13,   887,   314,  4137,  3589,\n",
      "           284,  1234,   340,   994,    26,   290,   783,   340,   338, 30703,\n",
      "           502,   438,    66,  1522,   502,    13,  1320,   338,   262,  1738,\n",
      "          1521,   314,   836,   470, 45553,   903,   597,   517,    11,   616,\n",
      "         13674,  8759,  2763,    26,   393,  2138,   520,  5493,  2241,   318,\n",
      "           262,  1738,   526,   198,   198,  1890,   262,   717,   640,   616,\n",
      "         21696, 20136,   546,   616, 15185,  2900,   656,   257,  2726,  6227,\n",
      "           284,  1833,   683,  1365,    13,   198,   198,     1,    40,  4601,\n",
      "           345,  1549,  1560,   502,   703,   340,  3022,   553,   314,   531,\n",
      "            13,   198,   198,  1544,  6204,  2045,   510,   379,   262, 17548,\n",
      "            11,   290,   665, 24297,  1022,   465,  9353,   257, 17779,   339,\n",
      "           550, 11564,   284,  1657,    13, 24975,   339,  2900,  3812,   502,\n",
      "            13,   198,   198,     1,    40,  1549,  2138,   588,   284,  1560,\n",
      "           345,   438, 13893,   314,  1053,  1464,  9885,   345,   286,  2376,\n",
      "         26927,   616,   670,   526,   198,   198,    40,   925,   257,  1207,\n",
      "          8344,   803, 18342,    11,   543,   339,  2469,   265,  1572,   351,\n",
      "           257,   922,    12, 17047,  8167, 32545,    13,   198,   198,     1,\n",
      "          5812,    11,   314,  1422,   470,  1337,   257, 14787,   618,   314,\n",
      "          4762,   287,  3589,   438,   392,   783,   340,   338,   281,  2087,\n",
      "          9839,  1022,   514,  2474,   198,   198],\n",
      "        [  292,   339,   550,   587,   832,    11,   290,   287, 15275,   286,\n",
      "            11,   465,  5986,   438,   568, 22665,    11,   523, 23332,    11,\n",
      "           523,   595, 18052,    11,   326,   530,   890,   276,   284,  3960,\n",
      "           503,    25,   366,  3856, 44455,   351,   534, 24638,  2474,   355,\n",
      "          1752,   530,   550,   890,   276,   284,   910,    25,   366,  3856,\n",
      "         44455,   351,   534,   670,  2474,   198,   198,  1537,    11,   351,\n",
      "           262,  3960,   319,   616, 11914,    11,   616, 13669,  6989,   281,\n",
      "         10059,  2198,    13,   198,   198,     1,  1212,   318,   616,   898,\n",
      "         49451,   553,   339,   531,    11,  3756,   502,   656,   257,  3223,\n",
      "          8631,  2119,   379,   262,   886,   286,   262,   781,   273,   312,\n",
      "           410, 12523,    13,   632,   373,  6616,   290,  7586,   290, 11620,\n",
      "            88,    25,   645,   366, 34435,  8172,   645,   865,   291,    12,\n",
      "            64,    12,  1671,   330,    11,  4844,   286,   262,  1633,   286,\n",
      "         24380,   329, 20728,   287,   257,  4286, 10273,   438, 29370,   477,\n",
      "            11,   645,  1551,  1051,   286,  1683,  1719,   587,   973,   355,\n",
      "           257,  8034,    13,   198,   198,   464,  1109,  3181,  1363,   284,\n",
      "           502,   262,  4112,   957,  1483,   286,  3619,   338,  2270,   351,\n",
      "           465,  1468,  1204,    13,   198,   198,     1,  3987,   470,   345,\n",
      "          1683, 45553,   903,   351,  7521,   597,   517,  1701,   314,  1965,\n",
      "            11,   991,  2045,   546,   329,   257, 12854,   286,   884,  3842,\n",
      "            13,   198,   198,     1, 12295,   553,   339,   531, 11589,    13,\n",
      "           198,   198,     1,  5574,  1660,    12, 49903,   438,   273,  2123,\n",
      "         10813,  1701,   198,   198,  6653,  6563,  2951,  6348,  5391,    11,\n",
      "           290,   465, 25839,   279,  3021,   257,  1310,   739,   511, 22665,\n",
      "          4252, 10899,    13,   198,   198,     1, 12295,   892,   286,   340,\n",
      "            11,   616, 13674,  5891,   438,  1092]])\n",
      "tensor([[  314,  4752,   340,  6777,    13,   632,   373,   407,   326,   616,\n",
      "          2583,   408,   373,   366, 47914,  1298,   319,   326,   966,   314,\n",
      "           714,   423,  1813,  4544,  9325,   701,   262, 40830, 12719,  3874,\n",
      "            13,   632,   373,   655,   780,   673,   373,  4808,  1662,    62,\n",
      "          3499,   438,   361,   314,   743,   307, 41746, 12004,   262,  6473,\n",
      "           438,  5562,   314,  1043,   607,   523,    13,  1114,  3619,    11,\n",
      "           477,   465,  1204,    11,   550,   587, 11191,   416,  3499,  1466,\n",
      "            25,   484,   550, 26546,  1068,   465,  1242,    11,   340,   550,\n",
      "           587,   302,  1144,   287,   262,  3024,    12,  4803,   286,   511,\n",
      "           512,  1741,    13,   843,   340,   373,  4361,  5048,   425,   284,\n",
      "          3465,   644,  1245,   262,   366, 25124,  3101,  8137,   286, 16957,\n",
      "          1696,   414,     1,   357,    40,  9577,  4544,  9325,   701,     8,\n",
      "           373,  1719,   319,   683,    13,   198,   198,    40,   423,  4750,\n",
      "           326,  9074,    13,   402,   271, 10899,   373,  5527,    26,   290,\n",
      "           340,   373,  3393, 34953,   856,   326,   607,  5229,   373, 37895,\n",
      "           422,   428, 25179,   257, 19217,   475,  8904, 14676,    13,   632,\n",
      "           318,    11,   355,   257,  3896,    11,   262,   661,   508, 40987,\n",
      "          1637,   508,   651,   749,   503,   286,   340,    26,   290,  3619,\n",
      "           338, 19992, 31564,   286,   465,  3656,   338,  1263,  5236,  9343,\n",
      "           683,    11,   351,   281,  5585,   286,  2818,   922,    12, 49705,\n",
      "            11,   284, 21595,  1133,   340,   656,  5563,   286,  1242,   290,\n",
      "         13064,    13,  1675,   262,  6846,    11,   314,  1276,   751,    11,\n",
      "           339,  6150,  5365, 31655,    26,   475,   339,   373,  7067, 29396,\n",
      "         18443, 12271,   290, 45592,    12, 14792,  5986,   351,   257,  8839,\n",
      "           326,  7284, 35924,   262, 12306,   395,  4133,    13,   198,   198,\n",
      "             1, 26788,   338,   691, 12226,   318],\n",
      "        [   11, 17728,   257,  8500,  4417,   284,   670,   319,   438, 15464,\n",
      "            11,   355,   340,   547,    11,   523, 16857,   262,  4469,   286,\n",
      "           607,   898,  4286,   438, 18108, 26269,  5223,   287,   281,  8468,\n",
      "          4922,   284,   262,  3359,   286,   428,  3991,  4118,    84, 16579,\n",
      "            13,   383,  4286,   373,   530,   286,  3619,   338,   366, 11576,\n",
      "           395,   553,   355,   465, 21099,  3808,   561,   423,  1234,   340,\n",
      "           438,   270,  7997,    11,   319,   465,   636,    11,   257, 29844,\n",
      "           286, 12749,    11,   257, 22791,   278,   286, 32375,    11,   257,\n",
      "         22486,    11,   965,  2860,  1359,   290,   965,  1397,    11,   326,\n",
      "         14516,   530,   286,   262, 33125,    12,   565,   593,   338, 25304,\n",
      "          4040,   284, 10303,   257, 17972,    13,   632,  1138,    11,   287,\n",
      "          1790,    11,   379,   790,   966,   262,  3512,   286, 14081,  2415,\n",
      "           284,   307, 13055,   366, 11576,   306,     1,   780,   673,   373,\n",
      "         10032,   286,   852, 13055,   366, 34751,   306,     1,   438,   392,\n",
      "          1865,   407,   284,  4425,   281, 22037,   286,   262, 32073,    13,\n",
      "           198,   198,     1,  1026,   338,   262,   938,   339, 13055,    11,\n",
      "           345,   760,   553,  9074,    13,   402,   271, 10899,   531,   351,\n",
      "         27322,   540, 11293,    13,   366,   464,   938,   475,   530,   553,\n",
      "           673, 19267,  5223,   438,     1,  4360,   262,   584,  1595,   470,\n",
      "           954,    11,   780,   339,  6572,   340,   526,   198,   198,     1,\n",
      "         49174,   276,   340,  1701,   314,   373,   546,   284,  1061,   510,\n",
      "           428, 18437,   618,   314,  2982,   257,  2366,  9662,   290,  2497,\n",
      "          3619,  2241,   319,   262, 11387,    13,   198,   198,  1722,   339,\n",
      "          6204,   612,    11,   465,  2832,   287,   262, 16511,   286,   465,\n",
      "         11555,   303,  7821, 13209,    11,   262,  7888,  7586,  9813,   286,\n",
      "          4190,  7121,   736,   422,   465,  2330]]) tensor([[ 4752,   340,  6777,    13,   632,   373,   407,   326,   616,  2583,\n",
      "           408,   373,   366, 47914,  1298,   319,   326,   966,   314,   714,\n",
      "           423,  1813,  4544,  9325,   701,   262, 40830, 12719,  3874,    13,\n",
      "           632,   373,   655,   780,   673,   373,  4808,  1662,    62,  3499,\n",
      "           438,   361,   314,   743,   307, 41746, 12004,   262,  6473,   438,\n",
      "          5562,   314,  1043,   607,   523,    13,  1114,  3619,    11,   477,\n",
      "           465,  1204,    11,   550,   587, 11191,   416,  3499,  1466,    25,\n",
      "           484,   550, 26546,  1068,   465,  1242,    11,   340,   550,   587,\n",
      "           302,  1144,   287,   262,  3024,    12,  4803,   286,   511,   512,\n",
      "          1741,    13,   843,   340,   373,  4361,  5048,   425,   284,  3465,\n",
      "           644,  1245,   262,   366, 25124,  3101,  8137,   286, 16957,  1696,\n",
      "           414,     1,   357,    40,  9577,  4544,  9325,   701,     8,   373,\n",
      "          1719,   319,   683,    13,   198,   198,    40,   423,  4750,   326,\n",
      "          9074,    13,   402,   271, 10899,   373,  5527,    26,   290,   340,\n",
      "           373,  3393, 34953,   856,   326,   607,  5229,   373, 37895,   422,\n",
      "           428, 25179,   257, 19217,   475,  8904, 14676,    13,   632,   318,\n",
      "            11,   355,   257,  3896,    11,   262,   661,   508, 40987,  1637,\n",
      "           508,   651,   749,   503,   286,   340,    26,   290,  3619,   338,\n",
      "         19992, 31564,   286,   465,  3656,   338,  1263,  5236,  9343,   683,\n",
      "            11,   351,   281,  5585,   286,  2818,   922,    12, 49705,    11,\n",
      "           284, 21595,  1133,   340,   656,  5563,   286,  1242,   290, 13064,\n",
      "            13,  1675,   262,  6846,    11,   314,  1276,   751,    11,   339,\n",
      "          6150,  5365, 31655,    26,   475,   339,   373,  7067, 29396, 18443,\n",
      "         12271,   290, 45592,    12, 14792,  5986,   351,   257,  8839,   326,\n",
      "          7284, 35924,   262, 12306,   395,  4133,    13,   198,   198,     1,\n",
      "         26788,   338,   691, 12226,   318,   284],\n",
      "        [17728,   257,  8500,  4417,   284,   670,   319,   438, 15464,    11,\n",
      "           355,   340,   547,    11,   523, 16857,   262,  4469,   286,   607,\n",
      "           898,  4286,   438, 18108, 26269,  5223,   287,   281,  8468,  4922,\n",
      "           284,   262,  3359,   286,   428,  3991,  4118,    84, 16579,    13,\n",
      "           383,  4286,   373,   530,   286,  3619,   338,   366, 11576,   395,\n",
      "           553,   355,   465, 21099,  3808,   561,   423,  1234,   340,   438,\n",
      "           270,  7997,    11,   319,   465,   636,    11,   257, 29844,   286,\n",
      "         12749,    11,   257, 22791,   278,   286, 32375,    11,   257, 22486,\n",
      "            11,   965,  2860,  1359,   290,   965,  1397,    11,   326, 14516,\n",
      "           530,   286,   262, 33125,    12,   565,   593,   338, 25304,  4040,\n",
      "           284, 10303,   257, 17972,    13,   632,  1138,    11,   287,  1790,\n",
      "            11,   379,   790,   966,   262,  3512,   286, 14081,  2415,   284,\n",
      "           307, 13055,   366, 11576,   306,     1,   780,   673,   373, 10032,\n",
      "           286,   852, 13055,   366, 34751,   306,     1,   438,   392,  1865,\n",
      "           407,   284,  4425,   281, 22037,   286,   262, 32073,    13,   198,\n",
      "           198,     1,  1026,   338,   262,   938,   339, 13055,    11,   345,\n",
      "           760,   553,  9074,    13,   402,   271, 10899,   531,   351, 27322,\n",
      "           540, 11293,    13,   366,   464,   938,   475,   530,   553,   673,\n",
      "         19267,  5223,   438,     1,  4360,   262,   584,  1595,   470,   954,\n",
      "            11,   780,   339,  6572,   340,   526,   198,   198,     1, 49174,\n",
      "           276,   340,  1701,   314,   373,   546,   284,  1061,   510,   428,\n",
      "         18437,   618,   314,  2982,   257,  2366,  9662,   290,  2497,  3619,\n",
      "          2241,   319,   262, 11387,    13,   198,   198,  1722,   339,  6204,\n",
      "           612,    11,   465,  2832,   287,   262, 16511,   286,   465, 11555,\n",
      "           303,  7821, 13209,    11,   262,  7888,  7586,  9813,   286,  4190,\n",
      "          7121,   736,   422,   465,  2330, 22645]])\n",
      "tensor([[12036,   683,     0,  3226,  1781,   314,  4001,   284,   466,   262,\n",
      "          4286,   329,  2147,   438,    40,  1297,  9074,    13,   520,  5493,\n",
      "           523,   618,   673,  2540,   284,   336,   321,   647,  1223,   546,\n",
      "           607,  8098,    13,   314,  3505,  1972,   572,   257, 40426, 10956,\n",
      "          9546,   546,   262, 15393,   852,  4808,  3810,    62,   438,  1219,\n",
      "            11,   314,   373, 19716,   306,    11,   616, 13674,  8759,  2763,\n",
      "             0,   314,   373, 24380,   284,  3589,   588,   530,   286,   616,\n",
      "           898,  1650,  1010,    13,   198,   198,     1,  6423,   314,   373,\n",
      "          2077,   510,   290,  1364,  3436,   351,   683,    13,   314,   550,\n",
      "          1908,   477,   616, 20348,   287,  5963,    11,   290,   314,   550,\n",
      "           691,   284,   900,   510,   262,  1396,   417,   290,   651,   284,\n",
      "           670,    13,   679,   550,   587,  2636,   691,  8208,    12, 14337,\n",
      "          2250,    11,   290,   339,  3724,  6451,    11,   286,  2612,  4369,\n",
      "            11,   523,   326,   612,   550,   587,   645, 15223,   670,   286,\n",
      "          8166,   438, 14363,  1986,   373,  1598,   290, 36519,    13,   314,\n",
      "           550,  1138,   683,  1752,   393,  5403,    11,   812,   878,    11,\n",
      "           290,  1807,   683, 32081,   290, 44852,    88,    13,  2735,   314,\n",
      "          2497,   326,   339,   373, 21840,    13,   198,   198,     1,    40,\n",
      "           373,  9675,   379,   717,    11,   351,   257,  6974, 19713, 14676,\n",
      "            25,  9675,   284,   423,   616,  1021,   319,   884,   257,   705,\n",
      "         32796,  2637,  3244,   465,  6283,  1204,    12, 46965,  9449,  2540,\n",
      "           284,  2689,   502, 24506,   306,   438,   292,   314, 10226,   262,\n",
      "          1182,   287,   314,  2936,   355,   611,   339,   547,  4964,   502,\n",
      "           466,   340,    13,   383, 18098,   373,  3940,   416,   262,  1807,\n",
      "            25,   611,   339,  4808, 22474,    62,  4964,   502,    11,   644,\n",
      "           561,   339,   910,   284,   616,   835],\n",
      "        [  284,  1234,  8737,   656, 19133,   553,   373,   530,   286,   262,\n",
      "          7877,    72,  3150,   339,  8104,   866,  1973,   262, 37918,   411,\n",
      "           290,  8465,   286,   281, 33954,   271,  3973,  9899, 14678, 40556,\n",
      "            12, 11487,    11,   618,    11,   319,   257,  1568,  1110,    11,\n",
      "           314,   550,   757,  1057,   625,   422, 22489, 40089,    26,   290,\n",
      "          9074,    13,   402,   271, 10899,    11,   307,  3723,   319,   683,\n",
      "            11,  2087,   329,   616, 35957,    25,   366, 14295,   318,   523,\n",
      "         34813,   306,  8564,   284,   790,  1296,   286,  8737,   526,   198,\n",
      "           198, 43920,  3619,     0,   632,   550,  1464,   587,   465, 10030,\n",
      "           284,   423,  1466,   910,   884,  1243,   286,   683,    25,   262,\n",
      "          1109,   815,   307,   900,   866,   287,  1070,   268,  2288,    13,\n",
      "          1867,  7425,   502,   783,   373,   326,    11,   329,   262,   717,\n",
      "           640,    11,   339,   581,  4714,   262,  8216,    13,   314,   550,\n",
      "          1775,   683,    11,   523,  1690,    11,  1615,  3364,   739,  2092,\n",
      "           256,  7657,   438,  9776,   340,   262, 11644, 43778,  3465,   326,\n",
      "         26773,   606,   286,   511,  6799,   454,    30,  1400,   438,  1640,\n",
      "            11, 31414,  1576,    11,   340,  2627,  4156,   326,   339,   373,\n",
      "         16245,   286,  9074,    13,   402,   271, 10899,   438,    69,   623,\n",
      "          1576,   407,   284,   766,   607, 41793,    13,   632,   373,   465,\n",
      "           898, 41793,   339,  3947,   284,   307,  1592,  2259,   739,   438,\n",
      "         14363,   898,  9408,   355,   281,  2134,   329,  5482,  4447,   290,\n",
      "           753,  1072,    13,   198,   198,     1,  3666, 13674,    11,  1201,\n",
      "           314,  1053,   442, 17758, 12036,   661,   836,   470,   910,   326,\n",
      "          3404,   546,   502,   438,  9930,   910,   340,   546, 12622, 41379,\n",
      "           293,   553,   373,   465,   691,  5402,    11,   355,   339,  8278,\n",
      "           422,   262,  3084,   290,   336,  8375]]) tensor([[  683,     0,  3226,  1781,   314,  4001,   284,   466,   262,  4286,\n",
      "           329,  2147,   438,    40,  1297,  9074,    13,   520,  5493,   523,\n",
      "           618,   673,  2540,   284,   336,   321,   647,  1223,   546,   607,\n",
      "          8098,    13,   314,  3505,  1972,   572,   257, 40426, 10956,  9546,\n",
      "           546,   262, 15393,   852,  4808,  3810,    62,   438,  1219,    11,\n",
      "           314,   373, 19716,   306,    11,   616, 13674,  8759,  2763,     0,\n",
      "           314,   373, 24380,   284,  3589,   588,   530,   286,   616,   898,\n",
      "          1650,  1010,    13,   198,   198,     1,  6423,   314,   373,  2077,\n",
      "           510,   290,  1364,  3436,   351,   683,    13,   314,   550,  1908,\n",
      "           477,   616, 20348,   287,  5963,    11,   290,   314,   550,   691,\n",
      "           284,   900,   510,   262,  1396,   417,   290,   651,   284,   670,\n",
      "            13,   679,   550,   587,  2636,   691,  8208,    12, 14337,  2250,\n",
      "            11,   290,   339,  3724,  6451,    11,   286,  2612,  4369,    11,\n",
      "           523,   326,   612,   550,   587,   645, 15223,   670,   286,  8166,\n",
      "           438, 14363,  1986,   373,  1598,   290, 36519,    13,   314,   550,\n",
      "          1138,   683,  1752,   393,  5403,    11,   812,   878,    11,   290,\n",
      "          1807,   683, 32081,   290, 44852,    88,    13,  2735,   314,  2497,\n",
      "           326,   339,   373, 21840,    13,   198,   198,     1,    40,   373,\n",
      "          9675,   379,   717,    11,   351,   257,  6974, 19713, 14676,    25,\n",
      "          9675,   284,   423,   616,  1021,   319,   884,   257,   705, 32796,\n",
      "          2637,  3244,   465,  6283,  1204,    12, 46965,  9449,  2540,   284,\n",
      "          2689,   502, 24506,   306,   438,   292,   314, 10226,   262,  1182,\n",
      "           287,   314,  2936,   355,   611,   339,   547,  4964,   502,   466,\n",
      "           340,    13,   383, 18098,   373,  3940,   416,   262,  1807,    25,\n",
      "           611,   339,  4808, 22474,    62,  4964,   502,    11,   644,   561,\n",
      "           339,   910,   284,   616,   835,   286],\n",
      "        [ 1234,  8737,   656, 19133,   553,   373,   530,   286,   262,  7877,\n",
      "            72,  3150,   339,  8104,   866,  1973,   262, 37918,   411,   290,\n",
      "          8465,   286,   281, 33954,   271,  3973,  9899, 14678, 40556,    12,\n",
      "         11487,    11,   618,    11,   319,   257,  1568,  1110,    11,   314,\n",
      "           550,   757,  1057,   625,   422, 22489, 40089,    26,   290,  9074,\n",
      "            13,   402,   271, 10899,    11,   307,  3723,   319,   683,    11,\n",
      "          2087,   329,   616, 35957,    25,   366, 14295,   318,   523, 34813,\n",
      "           306,  8564,   284,   790,  1296,   286,  8737,   526,   198,   198,\n",
      "         43920,  3619,     0,   632,   550,  1464,   587,   465, 10030,   284,\n",
      "           423,  1466,   910,   884,  1243,   286,   683,    25,   262,  1109,\n",
      "           815,   307,   900,   866,   287,  1070,   268,  2288,    13,  1867,\n",
      "          7425,   502,   783,   373,   326,    11,   329,   262,   717,   640,\n",
      "            11,   339,   581,  4714,   262,  8216,    13,   314,   550,  1775,\n",
      "           683,    11,   523,  1690,    11,  1615,  3364,   739,  2092,   256,\n",
      "          7657,   438,  9776,   340,   262, 11644, 43778,  3465,   326, 26773,\n",
      "           606,   286,   511,  6799,   454,    30,  1400,   438,  1640,    11,\n",
      "         31414,  1576,    11,   340,  2627,  4156,   326,   339,   373, 16245,\n",
      "           286,  9074,    13,   402,   271, 10899,   438,    69,   623,  1576,\n",
      "           407,   284,   766,   607, 41793,    13,   632,   373,   465,   898,\n",
      "         41793,   339,  3947,   284,   307,  1592,  2259,   739,   438, 14363,\n",
      "           898,  9408,   355,   281,  2134,   329,  5482,  4447,   290,   753,\n",
      "          1072,    13,   198,   198,     1,  3666, 13674,    11,  1201,   314,\n",
      "          1053,   442, 17758, 12036,   661,   836,   470,   910,   326,  3404,\n",
      "           546,   502,   438,  9930,   910,   340,   546, 12622, 41379,   293,\n",
      "           553,   373,   465,   691,  5402,    11,   355,   339,  8278,   422,\n",
      "           262,  3084,   290,   336,  8375,   503]])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x, y)\n",
    "    \n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2bfb325f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    logits_flat = logits.flatten(0,1)\n",
    "    targets_flat = target_batch.flatten()\n",
    "    loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "    return loss\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return total_loss\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i >= num_batches:\n",
    "            break\n",
    "        total_loss += calc_loss_batch(input_batch, target_batch, model, device).item()\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36146e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.987583584255642\n",
      "Validation loss: 10.98110580444336\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.to(device)\n",
    "torch.manual_seed(123) # For reproducibility due to the shuffling in the data loader\n",
    "\n",
    "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55f60bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7514e8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.781, Val loss 9.933\n",
      "Ep 1 (Step 000005): Train loss 8.111, Val loss 8.339\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010): Train loss 6.661, Val loss 7.048\n",
      "Ep 2 (Step 000015): Train loss 5.961, Val loss 6.616\n",
      "Every effort moves you, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and,, and, and,\n",
      "Ep 3 (Step 000020): Train loss 5.726, Val loss 6.600\n",
      "Ep 3 (Step 000025): Train loss 5.201, Val loss 6.348\n",
      "Every effort moves you, and I had been.                                            \n",
      "Ep 4 (Step 000030): Train loss 4.417, Val loss 6.278\n",
      "Ep 4 (Step 000035): Train loss 4.069, Val loss 6.226\n",
      "Every effort moves you know the                          \"I he had the donkey and I had the and I had the donkey and down the room, I had\n",
      "Ep 5 (Step 000040): Train loss 3.732, Val loss 6.160\n",
      "Every effort moves you know it was not that the picture--I had the fact by the last I had been--his, and in the            \"Oh, and he said, and down the room, and in\n",
      "Ep 6 (Step 000045): Train loss 2.850, Val loss 6.179\n",
      "Ep 6 (Step 000050): Train loss 2.427, Val loss 6.141\n",
      "Every effort moves you know,\" was one of the picture. The--I had a little of a little: \"Yes, and in fact, and in the picture was, and I had been at my elbow and as his pictures, and down the room, I had\n",
      "Ep 7 (Step 000055): Train loss 2.104, Val loss 6.134\n",
      "Ep 7 (Step 000060): Train loss 1.882, Val loss 6.233\n",
      "Every effort moves you know,\" was one of the picture for nothing--I told Mrs.  \"I was no--as! The women had been, in the moment--as Jack himself, as once one had been the donkey, and were, and in his\n",
      "Ep 8 (Step 000065): Train loss 1.320, Val loss 6.238\n",
      "Ep 8 (Step 000070): Train loss 0.985, Val loss 6.242\n",
      "Every effort moves you know,\" was one of the axioms he had been the tips of a self-confident moustache, I felt to see a smile behind his close grayish beard--as if he had the donkey. \"strongest,\" as his\n",
      "Ep 9 (Step 000075): Train loss 0.717, Val loss 6.293\n",
      "Ep 9 (Step 000080): Train loss 0.541, Val loss 6.393\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back the window-curtains, I had the donkey. \"There were days when I\n",
      "Ep 10 (Step 000085): Train loss 0.391, Val loss 6.452\n",
      "Every effort moves you know,\" was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed luncheon-table, when, on a later day, I had again run over from Monte Carlo; and Mrs. Gis\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b921c2b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82cc06d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you know,\" was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed lun\n"
     ]
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "model.eval()\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e96f9c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "vocab = { \n",
    "    \"closer\": 0,\n",
    "    \"every\": 1, \n",
    "    \"effort\": 2, \n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5, \n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "} \n",
    "\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}\n",
    "\n",
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")\n",
    "\n",
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "\n",
    "# The next generated token is then as follows:\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4be814a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "533c2f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "582 x forward\n",
      "2 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "343 x toward\n",
      "0 x you\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123) # Manual seed for reproducibility\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample), minlength=len(probas))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d1bb9b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id = None):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "        if top_k is not None:\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
    "        \n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "\n",
    "            # Sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "        \n",
    "        if idx_next == eos_id:\n",
    "            break\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9faf1c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you stand to work on surprise, a one of us had gone with random-\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a56145c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "01d6b6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.load_state_dict(torch.load(\"model.pth\", map_location=device, weights_only=True))\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b40ab7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    }, \n",
    "    \"model_and_optimizer.pth\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
